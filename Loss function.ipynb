{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function\n",
    "=============\n",
    "1. 損失函數（loss function）是用來估量模型的預測值f(x)與真實值Y的不一致程度\n",
    "2. 是一個非負實值函數,通常使用L(Y, f(x))來表示，損失函數越小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6480, 0.6302],\n",
      "        [0.1023, 0.6085]])\n",
      "tensor([[0.0649, 0.0987],\n",
      "        [0.4243, 0.3479]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.rand(2, 2) \n",
    "y = torch.rand(2, 2)\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.L1Loss(size_average=True)\n",
    "-----------------------------------------------------\n",
    "* loss(x,y) = 1/n∑|xi−yi|，X 與 Y 之間差的絕對值總和的平均\n",
    "* size_average 是 True 時會有 1/n，反之則沒有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4243)\n"
     ]
    }
   ],
   "source": [
    "lossFunc = torch.nn.L1Loss(size_average=True)\n",
    "loss = lossFunc(x, y)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.MSELoss(size_average=True)\n",
    "---------------------------------------------------------\n",
    "* loss(x,y) =  1/n∑(xi−yi)^2，X 與 Y 平方差總和的平均\n",
    "* size_average 是 True 時會有 1/n，反之則沒有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1985)\n"
     ]
    }
   ],
   "source": [
    "lossFunc = torch.nn.MSELoss(size_average=True)\n",
    "loss = lossFunc(x, y)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.NLLLoss(weight=None, size_average=True)\n",
    "--------------\n",
    "* 適用於訓練一個多分類器\n",
    "* weight: 為一個 1-D tensor，有 n 個元素，代表分類 n 類的權重\n",
    "* 在這個 loss func 的 target (y or class) 為 1—D tensor，表示分類的 label\n",
    "* 沒 weight: loss(x,class) = −x[class]\n",
    "* 有 weight: loss(x,class) = −weights[class]∗x[class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5926, -0.2742,  0.4403],\n",
      "        [-0.5851,  1.4676,  0.0196],\n",
      "        [-0.4039,  0.2867, -0.3413]])\n",
      "tensor([0, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 3) \n",
    "cls = torch.tensor([0, 2, 1]) \n",
    "\n",
    "print(x)\n",
    "print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0955)\n"
     ]
    }
   ],
   "source": [
    "lossFunc = torch.nn.NLLLoss()\n",
    "loss = lossFunc(x, cls)\n",
    "\n",
    "print(loss)  # (0.5926 - 0.0196 - 0.2867) / 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.CrossEntropyLoss(weight=None, size_average=True)\n",
    "------------------------------------------------------------\n",
    "* LogSoftMax 和 NLLLoss 混合使用 \n",
    "* 適用於訓練一個多分類器\n",
    "* weight: 為一個 1-D tensor，有 n 個元素，代表分類 n 類的權重\n",
    "* 在這個 loss func 的 target (y) 為 1—D tensor，表示分類的 label\n",
    "* 沒 weight: loss(x,class) = −x[class] + log(∑exp(x[i]))\n",
    "* 有 weight: loss(x,class)= weights[class]∗( −x[class] + log(∑exp(x[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3714)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\PytorchCuda\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\PytorchCuda\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1929, 0.2652, 0.5419],\n",
      "        [0.0942, 0.7334, 0.1724],\n",
      "        [0.2463, 0.4914, 0.2623]])\n",
      "tensor(1.3714)\n"
     ]
    }
   ],
   "source": [
    "# 方法一\n",
    "lossFunc = torch.nn.CrossEntropyLoss()\n",
    "loss = lossFunc(x, cls)\n",
    "\n",
    "print(loss)\n",
    "\n",
    "# 方法二\n",
    "sm = torch.nn.Softmax() # dim=1\n",
    "lossFunc = torch.nn.NLLLoss()\n",
    "loss = lossFunc(torch.log(sm(x)), cls)\n",
    "\n",
    "print(sm(x))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.NLLLoss2d(weight=None, size_average=True)\n",
    "---------------------------------------------------\n",
    "* 圖片用的 NLLLoss，用於計算每個像素的 NLL loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.3984,  0.7053,  0.1449,  ...,  2.3040,  1.0365,  1.5821],\n",
      "          [ 0.9656,  0.2370, -1.6854,  ...,  1.9406, -0.3339, -0.6145],\n",
      "          [-0.8265, -2.0631, -0.0204,  ...,  0.1132,  0.4101, -0.9964],\n",
      "          ...,\n",
      "          [-0.1297, -0.4821,  1.2247,  ...,  1.8557,  0.8339,  0.3337],\n",
      "          [ 0.3653,  0.8061, -1.3524,  ..., -1.3341,  0.2629,  1.0608],\n",
      "          [-1.4287,  2.7640,  0.1499,  ...,  0.3692, -1.2102, -0.6080]],\n",
      "\n",
      "         [[-2.5143, -0.1999,  0.3791,  ...,  1.6221,  1.4458, -1.6559],\n",
      "          [-0.6470, -0.5619, -0.0257,  ..., -0.6046, -0.5956, -0.6730],\n",
      "          [-0.1171,  1.4623, -0.7151,  ...,  0.9473, -0.3454,  0.3218],\n",
      "          ...,\n",
      "          [-0.1382,  0.7862, -0.8606,  ..., -0.6653, -1.2164,  0.7180],\n",
      "          [ 1.3261, -1.3438,  1.3809,  ...,  1.3329, -0.7151,  1.4915],\n",
      "          [-0.7864, -0.5958, -0.8480,  ...,  0.0865, -0.7058, -1.2478]],\n",
      "\n",
      "         [[-0.3136, -0.7026,  0.2152,  ...,  0.0718,  1.2367,  0.2311],\n",
      "          [-0.8856, -0.5319, -1.1393,  ...,  0.9151,  0.3838,  1.1045],\n",
      "          [ 0.1974,  0.3926, -0.7396,  ...,  0.2594, -1.3719, -1.5681],\n",
      "          ...,\n",
      "          [ 0.2541, -0.6421, -0.7730,  ..., -1.0078,  1.0021, -0.8749],\n",
      "          [-0.0448,  0.2951,  1.3549,  ...,  0.1446, -0.7851,  0.3035],\n",
      "          [-1.6596,  0.2580,  0.5405,  ...,  1.3159,  1.5049, -1.4684]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0660,  1.3739,  1.5330,  ...,  0.5480,  1.2290,  0.5936],\n",
      "          [-1.4169, -0.2335,  0.3165,  ...,  0.3445,  1.3326, -0.1947],\n",
      "          [-0.7025,  0.5735, -0.6720,  ...,  0.1226, -0.4187,  0.9363],\n",
      "          ...,\n",
      "          [-0.9803,  1.0300, -1.2796,  ...,  1.0321,  0.1694,  0.4231],\n",
      "          [-1.0242,  0.2609,  1.3680,  ...,  1.0206,  0.4651,  0.6298],\n",
      "          [-0.0055, -0.1287,  1.0511,  ...,  2.6146, -2.3283,  0.1261]],\n",
      "\n",
      "         [[-0.0158,  0.9408, -1.1818,  ..., -0.8738, -0.5285,  1.3297],\n",
      "          [-0.4141,  0.1577,  1.1719,  ...,  0.0751, -1.0808, -0.1836],\n",
      "          [-1.3116,  0.3815, -1.2061,  ..., -1.1957, -1.4630,  0.1946],\n",
      "          ...,\n",
      "          [-0.0207,  0.8359, -0.7353,  ...,  2.1050,  0.2716,  0.4172],\n",
      "          [ 1.3372,  1.0444,  0.9717,  ..., -0.2880,  1.4423,  1.9327],\n",
      "          [-1.3981, -0.2287,  1.4672,  ..., -0.0232, -1.4297,  0.3149]],\n",
      "\n",
      "         [[ 0.2182,  0.7724,  2.1863,  ..., -0.1442,  0.3292,  0.1497],\n",
      "          [ 0.6645,  1.1340,  0.6362,  ...,  0.6056,  0.0453, -0.1950],\n",
      "          [-1.7280, -1.3952,  0.6720,  ..., -2.7307, -0.0462, -0.7161],\n",
      "          ...,\n",
      "          [-0.1156,  0.1528,  1.3056,  ...,  0.6852,  0.7064, -0.0485],\n",
      "          [-0.2111,  1.6446,  0.9531,  ...,  1.4214, -1.3152,  0.4004],\n",
      "          [ 0.9283, -1.2019, -0.4018,  ..., -1.3948, -1.6942, -0.3156]]],\n",
      "\n",
      "\n",
      "        [[[-0.2786,  0.5841,  1.3889,  ...,  0.4677, -1.4980, -1.2722],\n",
      "          [-0.4982, -1.1560, -0.6874,  ..., -0.9229, -0.9616,  0.3723],\n",
      "          [-2.0298, -0.6290,  0.1249,  ..., -0.3588, -0.4025, -0.8187],\n",
      "          ...,\n",
      "          [-0.7463, -1.1622,  0.7535,  ...,  0.3636,  1.2911, -2.1268],\n",
      "          [ 0.3204,  0.6157, -1.2903,  ...,  0.0160,  1.2750, -0.7239],\n",
      "          [-0.2753,  0.2910,  1.5463,  ..., -1.3877,  1.4921, -0.7455]],\n",
      "\n",
      "         [[-0.6844, -1.5773, -0.4428,  ...,  0.3362, -0.4947, -0.2314],\n",
      "          [-1.3684, -1.4499, -1.2213,  ...,  0.0165,  1.2781,  0.3047],\n",
      "          [ 1.5211,  2.9194, -1.1989,  ...,  0.3906, -0.6151, -0.8512],\n",
      "          ...,\n",
      "          [-0.4418,  0.6363, -0.3277,  ..., -2.1648,  1.4931, -0.2895],\n",
      "          [-1.5285, -1.0731, -0.0350,  ..., -0.4844,  0.7694, -1.9589],\n",
      "          [-2.3819,  0.0433, -0.8537,  ...,  0.8088, -0.1374,  0.2078]],\n",
      "\n",
      "         [[ 0.4476, -0.7683, -0.3829,  ..., -0.2522,  0.5281, -1.2308],\n",
      "          [ 1.1665,  1.5914,  0.9962,  ...,  1.6138, -1.0144,  0.3173],\n",
      "          [-0.6917,  0.0215,  0.4685,  ..., -0.3610, -0.0813,  1.4763],\n",
      "          ...,\n",
      "          [-1.1952,  0.2682,  0.9051,  ...,  0.1476,  0.9298,  0.9681],\n",
      "          [-0.8997, -1.2203,  1.2885,  ...,  1.5142, -0.4132, -0.7524],\n",
      "          [-1.2651,  1.3717,  0.6112,  ...,  0.9736, -1.1589, -0.6472]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7076,  1.3837,  0.8077,  ...,  0.7559, -0.0431,  1.3004],\n",
      "          [ 0.3875, -0.4917, -0.9943,  ...,  0.1599, -0.1319,  0.6581],\n",
      "          [-0.2456,  0.3054, -0.6001,  ..., -0.4803, -1.1631,  0.1033],\n",
      "          ...,\n",
      "          [ 0.5235, -0.8132,  1.1587,  ...,  0.6961, -0.2265, -1.8705],\n",
      "          [ 0.7907,  0.2701,  1.5095,  ..., -0.2475, -1.3674,  1.3275],\n",
      "          [-0.0972,  2.6159,  3.3241,  ...,  0.2288,  0.2618, -0.2465]],\n",
      "\n",
      "         [[ 0.0309,  0.2248,  0.1492,  ..., -1.6077, -0.7845, -0.8140],\n",
      "          [-1.8040,  0.4704, -1.5524,  ..., -1.8458, -0.1446, -0.0868],\n",
      "          [ 0.2695, -0.7819, -0.1166,  ..., -1.1248, -1.0176,  0.2897],\n",
      "          ...,\n",
      "          [ 0.1358, -0.0633,  1.3269,  ...,  1.6197,  1.4041,  0.7656],\n",
      "          [ 1.5316, -0.1518,  1.0970,  ..., -0.7624,  1.8634,  1.0108],\n",
      "          [-2.0395,  0.3498, -1.2197,  ..., -1.3819, -1.4014, -0.6839]],\n",
      "\n",
      "         [[ 0.0933, -0.0453, -0.0613,  ..., -1.2836,  1.2171, -0.4359],\n",
      "          [ 0.4947,  0.1654,  0.5137,  ..., -0.2870,  0.9587, -0.0036],\n",
      "          [ 0.5455,  1.2291,  0.2480,  ..., -0.9029, -1.2303, -0.9432],\n",
      "          ...,\n",
      "          [-0.3873, -1.1134, -0.2036,  ...,  0.2759, -0.3310,  0.2204],\n",
      "          [-0.8171,  0.6722, -1.1431,  ...,  0.1422, -0.1569, -0.0406],\n",
      "          [ 0.0812,  0.7506, -0.7082,  ...,  0.5754, -0.5670, -0.5182]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6017, -0.9946,  0.4304,  ..., -0.6287,  1.3562,  1.2029],\n",
      "          [-0.2077,  0.4220,  0.1902,  ..., -0.5846, -0.5517, -0.0731],\n",
      "          [-0.1569,  0.9915,  0.5352,  ...,  0.9096,  2.4733,  0.6502],\n",
      "          ...,\n",
      "          [ 0.3396,  1.1017,  0.7349,  ...,  0.5957,  1.0054,  0.2602],\n",
      "          [ 0.2232,  0.3192, -0.4496,  ...,  0.5079,  0.7306,  0.7875],\n",
      "          [-1.2996,  1.0673, -0.8720,  ..., -0.0726,  0.9811,  0.8267]],\n",
      "\n",
      "         [[ 0.6506, -0.1933,  0.6753,  ..., -0.0363, -0.5207,  0.1520],\n",
      "          [-0.6927,  0.0637,  0.3042,  ...,  0.7179,  0.2701, -0.3128],\n",
      "          [-0.2675, -0.7478,  0.2590,  ...,  0.5980,  1.0932, -0.9233],\n",
      "          ...,\n",
      "          [-1.3001, -0.6231, -0.1477,  ...,  0.7460,  0.4428, -0.6624],\n",
      "          [ 1.0700, -1.0882,  1.5304,  ..., -0.5068,  1.1359,  0.3252],\n",
      "          [ 3.0584, -0.1388, -0.1526,  ..., -0.8883, -0.4063,  0.0900]],\n",
      "\n",
      "         [[-0.1690, -0.9776,  1.0934,  ..., -1.1087, -0.4712,  0.0479],\n",
      "          [-0.1946, -0.1404, -0.8121,  ..., -0.5809,  0.2535,  0.2661],\n",
      "          [-1.8177,  1.6542,  0.2314,  ..., -0.6307,  1.8573, -0.2116],\n",
      "          ...,\n",
      "          [-0.5523,  0.7164,  1.2052,  ...,  0.5424, -0.4595, -1.4265],\n",
      "          [ 0.7077, -0.0185,  0.2249,  ..., -0.5900,  1.3577,  0.6835],\n",
      "          [-0.4856, -0.2838, -0.9975,  ...,  0.4146,  2.0416,  1.0487]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1661,  0.0276,  0.4370,  ..., -1.0158, -0.3948, -0.2531],\n",
      "          [-0.0314,  0.6545,  0.3363,  ...,  0.6746, -0.6475,  0.9037],\n",
      "          [ 0.8373,  0.8239, -0.8183,  ..., -0.9615, -0.6699,  1.0966],\n",
      "          ...,\n",
      "          [-1.6128, -0.0418,  0.9346,  ...,  0.3719, -0.2547,  0.5420],\n",
      "          [-0.3844, -0.0381,  0.1203,  ...,  0.0676, -0.0863,  1.6479],\n",
      "          [ 0.5231, -1.0289, -1.4477,  ..., -0.0577, -0.6125, -0.6663]],\n",
      "\n",
      "         [[ 1.5936, -1.5259, -0.0414,  ..., -0.5444, -0.4698,  0.1866],\n",
      "          [-1.0030,  0.0390,  1.1706,  ...,  0.2515, -0.0381,  0.4722],\n",
      "          [ 1.7184, -0.2053,  0.8827,  ...,  1.6224,  0.3146,  0.6771],\n",
      "          ...,\n",
      "          [-0.7406,  1.2893, -1.2407,  ...,  0.1892,  1.2306, -1.4051],\n",
      "          [ 1.1167,  0.0205,  0.3138,  ..., -0.7305, -0.1152, -0.5277],\n",
      "          [ 1.0799,  0.7352, -0.8879,  ...,  1.2547,  2.2312,  1.0328]],\n",
      "\n",
      "         [[-0.8619, -0.4774, -0.8514,  ..., -0.6070,  0.1669, -0.1344],\n",
      "          [-1.0687,  0.8229, -0.1976,  ...,  0.6732, -0.0485,  0.9686],\n",
      "          [-1.0515, -0.7569, -0.2929,  ..., -1.1901,  0.3287,  0.4026],\n",
      "          ...,\n",
      "          [ 1.0628, -0.1652,  1.0850,  ...,  0.5243, -0.2874,  0.9666],\n",
      "          [ 0.7614, -0.4129, -1.4345,  ...,  1.2455,  0.7927,  0.3805],\n",
      "          [-0.9330, -1.7969,  1.7674,  ...,  0.9093,  0.8570, -0.5534]]]])\n",
      "tensor([[[1, 0, 1, 1, 2, 1, 1, 3],\n",
      "         [1, 1, 1, 2, 0, 1, 3, 2],\n",
      "         [0, 2, 2, 2, 0, 0, 3, 3],\n",
      "         [2, 3, 1, 0, 3, 0, 3, 1],\n",
      "         [0, 3, 3, 3, 3, 0, 1, 1],\n",
      "         [3, 3, 3, 3, 1, 1, 2, 2],\n",
      "         [3, 2, 2, 3, 2, 1, 3, 0],\n",
      "         [2, 1, 3, 2, 1, 3, 3, 0]],\n",
      "\n",
      "        [[0, 0, 3, 3, 1, 2, 1, 0],\n",
      "         [0, 2, 0, 0, 1, 2, 2, 1],\n",
      "         [0, 3, 2, 1, 2, 2, 3, 3],\n",
      "         [1, 1, 2, 1, 2, 2, 3, 1],\n",
      "         [3, 3, 3, 0, 1, 3, 0, 3],\n",
      "         [1, 0, 1, 0, 2, 1, 2, 2],\n",
      "         [3, 2, 0, 0, 3, 2, 0, 2],\n",
      "         [0, 3, 1, 2, 3, 2, 0, 1]],\n",
      "\n",
      "        [[3, 3, 1, 2, 2, 0, 1, 2],\n",
      "         [2, 1, 2, 2, 0, 2, 1, 0],\n",
      "         [0, 0, 0, 3, 0, 0, 3, 0],\n",
      "         [3, 2, 0, 2, 1, 1, 2, 2],\n",
      "         [0, 1, 3, 2, 1, 1, 3, 3],\n",
      "         [3, 0, 0, 1, 1, 2, 1, 3],\n",
      "         [0, 0, 1, 2, 2, 0, 2, 1],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         [3, 1, 2, 2, 1, 2, 3, 0]]])\n",
      "tensor([[[[ 0.3591,  0.1215, -0.3085,  ...,  0.8366, -0.2492,  0.2914],\n",
      "          [-0.8333,  0.8457,  0.4402,  ..., -0.2482, -0.4454, -0.0206],\n",
      "          [ 0.4764,  0.6606, -0.8394,  ...,  0.0243, -0.1197,  0.4161],\n",
      "          ...,\n",
      "          [-0.2185,  1.0834,  0.0232,  ...,  0.0164,  0.3782,  0.3701],\n",
      "          [-0.9340, -0.7330,  1.7110,  ..., -0.7615,  0.2861,  0.4030],\n",
      "          [ 0.2741, -1.3536, -0.3921,  ...,  1.0947,  0.0261,  0.4896]],\n",
      "\n",
      "         [[ 0.5690, -0.0072, -0.1599,  ..., -0.2423,  0.3337, -0.0021],\n",
      "          [-0.4071, -0.1257, -0.4732,  ..., -0.2291, -0.4400,  0.0704],\n",
      "          [-0.1936,  0.3703,  0.4253,  ..., -0.5221, -0.2592, -0.0507],\n",
      "          ...,\n",
      "          [ 0.5842, -0.4688,  0.1878,  ...,  0.0640, -0.2981, -0.0038],\n",
      "          [-0.1275,  1.6100, -0.0041,  ...,  0.4792,  0.4862,  0.6526],\n",
      "          [ 0.1363,  0.4072, -0.4499,  ...,  0.2179, -0.4641, -0.6671]],\n",
      "\n",
      "         [[ 0.3783, -0.9136,  0.6339,  ...,  0.3140, -1.5131, -0.1968],\n",
      "          [-0.1351, -0.5469, -0.0342,  ..., -0.6304,  0.4261, -0.3608],\n",
      "          [ 1.0827, -1.0209,  0.0196,  ..., -0.1701, -0.3589, -0.3675],\n",
      "          ...,\n",
      "          [-0.0044, -1.3287, -0.3703,  ...,  0.3959, -0.4550, -0.7005],\n",
      "          [-0.1652,  0.8735, -1.0113,  ...,  0.1933, -0.3072,  0.2424],\n",
      "          [-0.0405,  0.2926, -0.5066,  ..., -1.1413, -0.5641, -0.2576]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9276, -1.0926, -1.0487,  ...,  0.8006, -0.9203,  0.2925],\n",
      "          [ 0.2749,  0.5484, -0.7744,  ..., -0.2917, -0.3166,  0.0520],\n",
      "          [ 0.5054,  0.0698, -0.7706,  ...,  0.8474, -1.1391,  0.1016],\n",
      "          ...,\n",
      "          [ 0.4318, -0.4398, -0.1594,  ...,  0.9457,  0.1405, -0.0626],\n",
      "          [-0.6999, -0.0582, -0.1435,  ...,  0.4432, -0.2839,  1.1864],\n",
      "          [ 0.6520,  0.4636,  0.2449,  ...,  1.5947,  0.2439, -0.4915]],\n",
      "\n",
      "         [[-0.3108, -0.7380,  0.3992,  ..., -0.1676, -0.0136, -0.2759],\n",
      "          [-0.9927, -0.9607, -0.0460,  ...,  0.3593,  0.1540,  0.4588],\n",
      "          [ 0.1227, -0.6639,  0.4440,  ...,  0.3541, -0.8534, -0.0605],\n",
      "          ...,\n",
      "          [-0.3943, -0.7609,  0.1821,  ..., -0.1836,  0.4048, -1.0452],\n",
      "          [-0.1904,  0.3293, -0.1282,  ..., -0.5105,  0.5512,  0.6870],\n",
      "          [ 0.7149, -0.7395, -1.3145,  ...,  0.6995,  0.2403,  0.3328]],\n",
      "\n",
      "         [[-0.1764, -0.6694,  0.0221,  ..., -0.6651, -1.5758, -0.5043],\n",
      "          [-0.0915, -0.0231, -0.4904,  ..., -0.2246,  0.0064,  0.2252],\n",
      "          [-0.5149, -0.6294, -0.2008,  ...,  0.4974, -0.4249, -1.0122],\n",
      "          ...,\n",
      "          [ 0.1683, -0.9689, -0.1079,  ..., -0.2722,  0.1189, -0.3462],\n",
      "          [ 0.2239,  0.0026, -0.7600,  ..., -0.3261, -0.1640,  0.1115],\n",
      "          [-1.2688, -0.5941, -0.3238,  ..., -0.2642, -0.2379, -0.6316]]],\n",
      "\n",
      "\n",
      "        [[[-0.2295,  0.4298,  0.2795,  ...,  0.1060,  1.2549,  0.4447],\n",
      "          [-0.1972, -0.1654, -0.4422,  ..., -0.1751, -0.2941,  0.4781],\n",
      "          [ 0.5339, -1.9052,  0.8372,  ..., -0.3274,  0.3482,  0.7568],\n",
      "          ...,\n",
      "          [ 0.6393, -0.8984,  0.1543,  ...,  0.4822, -0.3751,  0.1436],\n",
      "          [ 0.2993, -0.5031,  0.1177,  ..., -0.6771, -0.5670, -0.1684],\n",
      "          [ 0.1742,  0.4184, -0.6152,  ...,  0.7046,  0.1517,  0.2627]],\n",
      "\n",
      "         [[ 0.5791, -0.0338, -1.2456,  ...,  0.0106, -0.5009, -0.7671],\n",
      "          [ 0.1875,  0.0407,  0.8448,  ..., -0.1116,  0.2914,  0.2126],\n",
      "          [-1.0107, -0.4840, -0.3656,  ..., -0.4578,  0.3707, -0.3896],\n",
      "          ...,\n",
      "          [ 0.1900,  0.1008,  0.4226,  ...,  0.6649,  0.2049,  0.0633],\n",
      "          [ 0.9418,  1.3790,  0.1276,  ...,  0.5562,  0.4515, -0.3013],\n",
      "          [ 1.7698,  0.7023, -0.3142,  ..., -0.3067, -0.0687, -0.8901]],\n",
      "\n",
      "         [[-0.6497,  0.9479, -0.8226,  ..., -1.6405,  0.0664, -0.0234],\n",
      "          [ 1.3814, -0.2297,  0.0281,  ...,  0.5802,  0.0227, -0.3785],\n",
      "          [-0.3413,  0.1395, -0.9575,  ...,  0.0187,  0.3937, -1.2752],\n",
      "          ...,\n",
      "          [-0.1022,  0.3776,  0.3410,  ..., -1.3237,  0.7944, -0.7781],\n",
      "          [-0.5141, -0.1342,  0.3155,  ...,  0.1290,  0.2324, -0.7830],\n",
      "          [-0.5886,  0.1581,  0.0102,  ..., -0.8746,  0.3011,  0.4682]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3132,  0.3085, -1.5323,  ..., -0.5284,  0.5349,  0.4240],\n",
      "          [-0.1129, -0.0028,  0.5596,  ...,  0.6789, -0.0332, -0.9138],\n",
      "          [-0.1621, -0.5655,  1.9263,  ..., -0.1421,  0.9003, -0.3102],\n",
      "          ...,\n",
      "          [ 1.6502,  0.5438,  0.4457,  ..., -1.1436,  1.2605,  0.2471],\n",
      "          [-0.4050,  0.0570,  0.1807,  ...,  0.1440, -0.0938, -0.0703],\n",
      "          [-0.8976,  1.5273, -0.1059,  ...,  0.5054,  0.2182, -0.8521]],\n",
      "\n",
      "         [[-0.0612, -0.1155, -0.0072,  ..., -0.2383,  0.7289, -0.5567],\n",
      "          [-0.1132, -0.2413, -0.7381,  ...,  0.6793, -0.2004, -0.1309],\n",
      "          [-0.4821,  0.8350, -0.2353,  ..., -0.2953, -0.0792,  0.0992],\n",
      "          ...,\n",
      "          [ 0.1387, -0.0344, -0.3665,  ...,  0.0521,  0.7162, -0.1682],\n",
      "          [-0.0081, -0.1940,  0.5638,  ..., -0.3033,  0.4479, -0.7632],\n",
      "          [-0.7228, -0.0939, -0.3710,  ...,  0.0937,  0.4935,  0.3066]],\n",
      "\n",
      "         [[-0.7928, -0.0388, -0.1602,  ...,  0.4545,  0.0394, -0.6190],\n",
      "          [ 0.8493,  0.0132, -0.0050,  ...,  0.3913, -0.3526, -0.1055],\n",
      "          [-1.1787, -0.3023, -0.6653,  ..., -1.2229,  0.3323,  0.0699],\n",
      "          ...,\n",
      "          [-0.9838, -0.6912, -0.6273,  ..., -0.7834, -0.0182, -0.7589],\n",
      "          [-0.0273, -0.1052, -0.8330,  ..., -0.3227, -0.3230, -0.2491],\n",
      "          [-0.1025, -1.6780, -0.5241,  ..., -0.2629,  0.2293,  1.3874]]],\n",
      "\n",
      "\n",
      "        [[[-0.1418, -0.3137, -0.8830,  ...,  0.8273, -0.5409,  0.1198],\n",
      "          [ 0.3911,  1.3865,  1.2815,  ...,  0.2373, -0.0650,  0.1886],\n",
      "          [ 0.0785, -0.2139,  0.5203,  ...,  0.1439,  0.3020, -1.0952],\n",
      "          ...,\n",
      "          [-0.0022,  0.6338,  0.2525,  ...,  0.3369,  0.3270, -0.1648],\n",
      "          [-0.2228, -0.7471,  0.3880,  ..., -0.7952, -0.1008, -0.2757],\n",
      "          [ 0.4476,  0.3530, -0.2597,  ...,  0.4196, -0.9259, -0.6564]],\n",
      "\n",
      "         [[ 0.5739, -0.9652,  0.1278,  ...,  0.3509,  0.0942,  0.1906],\n",
      "          [ 0.0739, -0.7017,  0.0834,  ..., -0.6285, -0.7620,  0.9428],\n",
      "          [ 0.3581,  0.0485, -0.2046,  ..., -0.1629, -0.3295, -0.6376],\n",
      "          ...,\n",
      "          [ 0.1247,  0.7974,  1.1713,  ...,  0.0825,  0.0682, -0.4347],\n",
      "          [-0.1747, -0.2006, -0.8695,  ..., -0.1891,  0.8020,  1.1683],\n",
      "          [-1.0615,  0.5844,  0.3821,  ...,  0.5602,  0.4325,  0.3582]],\n",
      "\n",
      "         [[-1.0263,  0.8462, -0.5080,  ...,  0.4548,  1.1209, -0.0449],\n",
      "          [ 0.1848, -0.5352,  0.3324,  ..., -0.4632,  0.1653, -1.0881],\n",
      "          [ 0.2898, -0.4936, -0.2198,  ..., -1.5650, -0.8267, -0.8602],\n",
      "          ...,\n",
      "          [ 0.0597,  0.0408, -0.7176,  ..., -0.5488, -0.2998,  0.0939],\n",
      "          [ 0.3176, -0.4933, -0.9074,  ...,  1.6624, -0.0632,  1.0596],\n",
      "          [-0.5583, -0.9826, -0.3002,  ..., -0.3203,  0.3084, -0.4285]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9048,  0.0698, -0.1949,  ...,  1.6863,  1.1712, -0.3537],\n",
      "          [-0.0088,  0.6386, -0.0319,  ...,  0.4745,  0.1013,  0.1221],\n",
      "          [-1.0799,  0.5579,  0.1736,  ..., -0.1482,  0.6054, -0.1250],\n",
      "          ...,\n",
      "          [-0.9156, -0.2549,  0.0599,  ..., -0.8522, -0.6406, -0.1525],\n",
      "          [ 0.5014,  0.6163,  0.1458,  ...,  0.7169, -0.2625,  1.1653],\n",
      "          [-0.7535, -0.0810, -0.6655,  ...,  0.1664,  0.7576,  0.5183]],\n",
      "\n",
      "         [[ 0.4700,  0.3314,  0.8087,  ...,  1.2484,  0.3179, -0.3047],\n",
      "          [ 0.2931,  0.2375,  0.3353,  ...,  0.6485,  0.8283,  0.5138],\n",
      "          [-0.0681, -0.8381,  0.3299,  ..., -0.3591,  0.7630,  0.4320],\n",
      "          ...,\n",
      "          [-0.1342,  0.5817,  0.2358,  ..., -0.6028, -0.6957, -0.3759],\n",
      "          [ 0.6516, -0.4210, -0.2011,  ..., -0.5463,  0.7615,  0.4568],\n",
      "          [-0.3140, -0.0751,  0.5310,  ...,  0.6846,  0.5211, -0.2027]],\n",
      "\n",
      "         [[-0.4901, -0.2778, -0.1866,  ..., -0.1495, -0.3368, -0.3832],\n",
      "          [ 0.0519, -0.3771, -0.1490,  ..., -0.2976, -0.0674,  0.3849],\n",
      "          [-0.4480,  0.6425,  0.1675,  ..., -0.5635, -0.4371, -0.2125],\n",
      "          ...,\n",
      "          [ 0.5971,  0.3388,  0.3595,  ...,  0.0116, -0.3947, -0.0043],\n",
      "          [ 1.4299, -0.6051,  0.0369,  ..., -0.6527,  0.4689,  0.1484],\n",
      "          [ 0.6194,  0.1911,  0.0627,  ..., -0.2780,  0.3293,  1.0040]]]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<ThnnConv2DBackward>)\n",
      "tensor(0.0246, grad_fn=<NllLoss2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "m = torch.nn.Conv2d(16, 32, (3, 3)).float()\n",
    "\n",
    "loss = torch.nn.NLLLoss2d()\n",
    "\n",
    "# input is of size nBatch x nClasses x height x width\n",
    "input = torch.autograd.Variable(torch.randn(3, 16, 10, 10))\n",
    "print(input)\n",
    "\n",
    "# each element in target has to have 0 <= value < nclasses\n",
    "target = torch.autograd.Variable(torch.LongTensor(3, 8, 8).random_(0, 4))\n",
    "print(target)\n",
    "\n",
    "output = loss(m(input), target)\n",
    "print(m(input))\n",
    "print(output)\n",
    "\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.KLDivLoss(weight=None, size_average=True)\n",
    "-------------------------------------------------\n",
    "* KL 散度損失，KL散度常用來描述兩個分佈的距離\n",
    "* loss(x, target ) = 1/n∑(target_i ∗ (log(target_i) − x_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.MarginRankingLoss(margin=0, size_average=True)\n",
    "----------------------------------------------------\n",
    "* loss(x,y) = max(0, −y∗(x1 − x2) + margin)，x1 與 x2 為 1-D mini-batch Tensor，y 為 -1 或 1 的 1-D mini-batch Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.HingeEmbeddingLoss(size_average=True)\n",
    "------------------------------------------------\n",
    "* 给定一个输入 x(2-D mini-batch tensor)和对应的 标签 y (1-D tensor,1,-1)，此函数用来计算之间的损失值。\n",
    "* loss(x,y) = 1/n ∑{xi, if yi == 1 max(0, margin−xi), if yi==−1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
